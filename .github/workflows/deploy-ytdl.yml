name: Deploy ytdl Service

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  deploy:
    name: Build and Deploy to EC2
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ytdl
          IMAGE_TAG: ${{ github.sha }}
        working-directory: ./apps/ytdl
        run: |
          docker build --platform linux/amd64 -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Deploy to EC2
        uses: appleboy/ssh-action@v1.0.0
        env:
          IMAGE_TAG: ${{ github.sha }}
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd /home/ec2-user/ytdl
            
            export IMAGE_TAG="${{ github.sha }}"
            echo "ðŸ“¦ Deploying image tag: $IMAGE_TAG"
            
            echo "ðŸ”’ Architecture: multi-worker VPN (3 gluetun + 3 workers + manager)"
            echo "ðŸ“¦ ALL secrets fetched from AWS Secrets Manager"
            echo ""
            
            # Generate docker-compose.yml with multi-worker architecture
            cat > docker-compose.yml << 'COMPOSE_EOF'
            services:
              manager:
                image: 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl:IMAGE_TAG_PLACEHOLDER
                container_name: manager
                command: ["npx", "ts-node", "manager.ts"]
                ports:
                  - "3001:3001"
                environment:
                  - MANAGER_PORT=3001
                  - YTDL_HOST=ytdl
                  - YTDL_PORT=3001
                  - GLUETUN_CONTAINERS=gluetun-1,gluetun-2,gluetun-3
                  - WORKER_CONTAINERS=worker-1,worker-2,worker-3
                  - MANAGER_CONTAINER=manager
                  - YTDL_CONTAINER=ytdl
                  - REDIS_CONTAINER=redis
                volumes:
                  - /var/run/docker.sock:/var/run/docker.sock
                  - /proc/meminfo:/host/proc/meminfo:ro
                  - ./manager-data:/data
                depends_on:
                  gluetun-1:
                    condition: service_started
                  gluetun-2:
                    condition: service_started
                  gluetun-3:
                    condition: service_started
                networks:
                  - ytdl-network
                restart: unless-stopped
                mem_limit: 256m

              ytdl:
                image: 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl:IMAGE_TAG_PLACEHOLDER
                container_name: ytdl
                networks:
                  - ytdl-network
                depends_on:
                  redis:
                    condition: service_started
                environment:
                  - NODE_ENV=production
                  - PORT=3001
                  - REDIS_HOST=redis
                  - REDIS_PORT=6379
                  - YTDL_INTERNAL_API_KEY=${YTDL_INTERNAL_API_KEY}
                  - DATABASE_URL=${DATABASE_URL}
                  - WORKER_ENDPOINTS=gluetun-1:3001,gluetun-2:3001,gluetun-3:3001
                restart: unless-stopped
                mem_limit: 512m

              gluetun-1:
                image: qmcgaw/gluetun:v3.41.1
                container_name: gluetun-1
                cap_add:
                  - NET_ADMIN
                devices:
                  - /dev/net/tun:/dev/net/tun
                environment:
                  - VPN_SERVICE_PROVIDER=nordvpn
                  - OPENVPN_USER=${NORDVPN_USERNAME}
                  - OPENVPN_PASSWORD=${NORDVPN_PASSWORD}
                  - SERVER_CITIES=New York
                  - LOG_LEVEL=info
                  - FIREWALL_OUTBOUND_SUBNETS=172.16.0.0/12,192.168.0.0/16,10.0.0.0/8
                  - FIREWALL_INPUT_PORTS=3001
                volumes:
                  - ./gluetun-1-data:/gluetun
                restart: unless-stopped
                mem_limit: 256m
                healthcheck:
                  test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://www.google.com"]
                  interval: 30s
                  timeout: 10s
                  retries: 3
                networks:
                  - ytdl-network

              gluetun-2:
                image: qmcgaw/gluetun:v3.41.1
                container_name: gluetun-2
                cap_add:
                  - NET_ADMIN
                devices:
                  - /dev/net/tun:/dev/net/tun
                environment:
                  - VPN_SERVICE_PROVIDER=nordvpn
                  - OPENVPN_USER=${NORDVPN_USERNAME}
                  - OPENVPN_PASSWORD=${NORDVPN_PASSWORD}
                  - SERVER_CITIES=Chicago
                  - LOG_LEVEL=info
                  - FIREWALL_OUTBOUND_SUBNETS=172.16.0.0/12,192.168.0.0/16,10.0.0.0/8
                  - FIREWALL_INPUT_PORTS=3001
                volumes:
                  - ./gluetun-2-data:/gluetun
                restart: unless-stopped
                mem_limit: 256m
                healthcheck:
                  test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://www.google.com"]
                  interval: 30s
                  timeout: 10s
                  retries: 3
                networks:
                  - ytdl-network

              gluetun-3:
                image: qmcgaw/gluetun:v3.41.1
                container_name: gluetun-3
                cap_add:
                  - NET_ADMIN
                devices:
                  - /dev/net/tun:/dev/net/tun
                environment:
                  - VPN_SERVICE_PROVIDER=nordvpn
                  - OPENVPN_USER=${NORDVPN_USERNAME}
                  - OPENVPN_PASSWORD=${NORDVPN_PASSWORD}
                  - SERVER_CITIES=Los Angeles
                  - LOG_LEVEL=info
                  - FIREWALL_OUTBOUND_SUBNETS=172.16.0.0/12,192.168.0.0/16,10.0.0.0/8
                  - FIREWALL_INPUT_PORTS=3001
                volumes:
                  - ./gluetun-3-data:/gluetun
                restart: unless-stopped
                mem_limit: 256m
                healthcheck:
                  test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://www.google.com"]
                  interval: 30s
                  timeout: 10s
                  retries: 3
                networks:
                  - ytdl-network

              worker-1:
                image: 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl:IMAGE_TAG_PLACEHOLDER
                container_name: worker-1
                command: ["npx", "ts-node", "worker.ts"]
                network_mode: "service:gluetun-1"
                depends_on:
                  gluetun-1:
                    condition: service_started
                environment:
                  - WORKER_ID=worker-1
                  - WORKER_PORT=3001
                restart: unless-stopped
                mem_limit: 384m

              worker-2:
                image: 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl:IMAGE_TAG_PLACEHOLDER
                container_name: worker-2
                command: ["npx", "ts-node", "worker.ts"]
                network_mode: "service:gluetun-2"
                depends_on:
                  gluetun-2:
                    condition: service_started
                environment:
                  - WORKER_ID=worker-2
                  - WORKER_PORT=3001
                restart: unless-stopped
                mem_limit: 384m

              worker-3:
                image: 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl:IMAGE_TAG_PLACEHOLDER
                container_name: worker-3
                command: ["npx", "ts-node", "worker.ts"]
                network_mode: "service:gluetun-3"
                depends_on:
                  gluetun-3:
                    condition: service_started
                environment:
                  - WORKER_ID=worker-3
                  - WORKER_PORT=3001
                restart: unless-stopped
                mem_limit: 384m

              redis:
                image: redis:alpine
                container_name: redis
                command: ["redis-server", "--appendonly", "yes", "--dir", "/data"]
                volumes:
                  - ./redis-data:/data
                restart: unless-stopped
                mem_limit: 128m
                networks:
                  - ytdl-network

            networks:
              ytdl-network:
                driver: bridge
            COMPOSE_EOF
            
            # Replace image tag placeholder
            sed -i "s|IMAGE_TAG_PLACEHOLDER|$IMAGE_TAG|g" docker-compose.yml
            
            echo "âœ… docker-compose.yml generated (multi-worker VPN architecture)"
            
            # Load ALL secrets from AWS Secrets Manager on the HOST
            echo "ðŸ” Loading secrets from AWS Secrets Manager..."
            export NORDVPN_USERNAME=$(aws secretsmanager get-secret-value --region us-east-1 --secret-id hermitcraft-horns/ytdl/nordvpn-username --query SecretString --output text)
            export NORDVPN_PASSWORD=$(aws secretsmanager get-secret-value --region us-east-1 --secret-id hermitcraft-horns/ytdl/nordvpn-password --query SecretString --output text)
            export YTDL_INTERNAL_API_KEY=$(aws secretsmanager get-secret-value --region us-east-1 --secret-id hermitcraft-horns/ytdl/api-key --query SecretString --output text)
            export DATABASE_URL=$(aws secretsmanager get-secret-value --region us-east-1 --secret-id hermitcraft-horns/ytdl/database-url --query SecretString --output text)
            
            echo "âœ… All secrets loaded from AWS!"
            echo "   NORDVPN_USERNAME: ${NORDVPN_USERNAME:0:3}***"
            echo "   YTDL_INTERNAL_API_KEY: ${YTDL_INTERNAL_API_KEY:0:8}***"
            echo "   DATABASE_URL: ${DATABASE_URL:0:20}***"
            
            # Clean up old Docker resources
            echo ""
            echo "ðŸ—‘ï¸  Cleaning up old Docker resources..."
            docker container prune -f
            docker image prune -f
            docker images 851725492026.dkr.ecr.us-east-1.amazonaws.com/ytdl --format "{{.ID}} {{.Tag}}" | grep -v "$IMAGE_TAG" | awk '{print $1}' | xargs -r docker rmi -f || true
            # NOTE: do NOT run `docker volume prune -f` here â€” it destroys
            # persistent bind-mount data (Redis AOF, manager history) between deploys
            echo "âœ… Cleanup complete"
            
            # Log in to ECR and pull latest images
            echo ""
            echo "ðŸ“¥ Pulling fresh images..."
            aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 851725492026.dkr.ecr.us-east-1.amazonaws.com
            docker-compose pull ytdl manager worker-1 worker-2 worker-3
            docker-compose pull gluetun-1 gluetun-2 gluetun-3
            
            # Bring down old containers (--remove-orphans removes old single-vpn containers)
            docker-compose down --remove-orphans
            
            # Start containers
            docker-compose up -d --force-recreate --remove-orphans
            
            echo ""
            echo "â³ Waiting for services to start..."
            sleep 15
            
            echo ""
            echo "=== Container status ==="
            docker-compose ps
            
            echo ""
            echo "=== Manager logs ==="
            docker-compose logs --tail=10 manager
            
            echo ""
            echo "=== ytdl logs ==="
            docker-compose logs --tail=15 ytdl
            
            echo ""
            echo "=== VPN status (gluetun-1) ==="
            docker-compose logs --tail=10 gluetun-1 | grep -E "Public IP|AUTH|healthy|openvpn|FIREWALL" || true
            echo ""
            echo "=== VPN status (gluetun-2) ==="
            docker-compose logs --tail=10 gluetun-2 | grep -E "Public IP|AUTH|healthy|openvpn|FIREWALL" || true
            echo ""
            echo "=== VPN status (gluetun-3) ==="
            docker-compose logs --tail=10 gluetun-3 | grep -E "Public IP|AUTH|healthy|openvpn|FIREWALL" || true
            
            echo ""
            echo "=== Final container status ==="
            docker-compose ps

      - name: Notify deployment status
        if: always()
        run: |
          if [ ${{ job.status }} == 'success' ]; then
            echo "âœ… ytdl service deployed successfully!"
          else
            echo "âŒ ytdl deployment failed!"
          fi
